{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/hamdi_ug/anaconda3/envs/strgn:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                        main  \n",
      "argon2-cffi               20.1.0           py36h8c4c3a4_1    conda-forge\n",
      "attrs                     19.3.0                     py_0    conda-forge\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\n",
      "backports                 1.0                        py_2    conda-forge\n",
      "backports.functools_lru_cache 1.6.1                      py_0    conda-forge\n",
      "blas                      1.0                         mkl  \n",
      "bleach                    3.1.5              pyh9f0ad1d_0    conda-forge\n",
      "bzip2                     1.0.8                h516909a_2    conda-forge\n",
      "ca-certificates           2020.6.24                     0    anaconda\n",
      "certifi                   2020.6.20                py36_0    anaconda\n",
      "cffi                      1.14.1           py36h0ff685e_0    conda-forge\n",
      "cudatoolkit               10.1.243             h6bb024c_0  \n",
      "cycler                    0.10.0                   pypi_0    pypi\n",
      "decorator                 4.4.2                      py_0    conda-forge\n",
      "defusedxml                0.6.0                      py_0    conda-forge\n",
      "entrypoints               0.3             py36h9f0ad1d_1001    conda-forge\n",
      "ffmpeg                    4.0.2                ha0c5888_2    conda-forge\n",
      "ffmpeg-python             0.2.0                    pypi_0    pypi\n",
      "freetype                  2.10.2               h5ab3b9f_0  \n",
      "future                    0.18.2                   pypi_0    pypi\n",
      "gmp                       6.1.2             hf484d3e_1000    conda-forge\n",
      "gnutls                    3.5.19               h2a4e5f8_1    conda-forge\n",
      "imageio                   2.9.0                    pypi_0    pypi\n",
      "importlib-metadata        1.7.0            py36h9f0ad1d_0    conda-forge\n",
      "importlib_metadata        1.7.0                         0    conda-forge\n",
      "intel-openmp              2020.1                      217  \n",
      "ipykernel                 5.3.4            py36h95af2a2_0    conda-forge\n",
      "ipython                   7.16.1           py36h95af2a2_0    conda-forge\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\n",
      "jedi                      0.17.2           py36h9f0ad1d_0    conda-forge\n",
      "jinja2                    2.11.2             pyh9f0ad1d_0    conda-forge\n",
      "jpeg                      9b                   h024ee3a_2  \n",
      "jsonschema                3.2.0            py36h9f0ad1d_1    conda-forge\n",
      "jupyter_client            6.1.6                      py_0    conda-forge\n",
      "jupyter_core              4.6.3            py36h9f0ad1d_1    conda-forge\n",
      "kiwisolver                1.2.0                    pypi_0    pypi\n",
      "lcms2                     2.11                 h396b838_0  \n",
      "libedit                   3.1.20191231         h14c3975_1  \n",
      "libffi                    3.2.1                hd88cf55_4  \n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \n",
      "libiconv                  1.15              h516909a_1006    conda-forge\n",
      "libpng                    1.6.37               hbc83047_0  \n",
      "libsodium                 1.0.18               h516909a_0    conda-forge\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \n",
      "libtiff                   4.1.0                h2733197_1  \n",
      "lz4-c                     1.9.2                he6710b0_1  \n",
      "markupsafe                1.1.1            py36h8c4c3a4_1    conda-forge\n",
      "matplotlib                3.3.1                    pypi_0    pypi\n",
      "mistune                   0.8.4           py36h8c4c3a4_1001    conda-forge\n",
      "mkl                       2020.1                      217  \n",
      "mkl-service               2.3.0            py36he904b0f_0  \n",
      "mkl_fft                   1.1.0            py36h23d657b_0  \n",
      "mkl_random                1.1.1            py36h0573a6f_0  \n",
      "munch                     2.5.0                    pypi_0    pypi\n",
      "nbconvert                 5.6.1            py36h9f0ad1d_1    conda-forge\n",
      "nbformat                  5.0.7                      py_0    conda-forge\n",
      "ncurses                   6.2                  he6710b0_1  \n",
      "nettle                    3.3                           0    conda-forge\n",
      "networkx                  2.4                      pypi_0    pypi\n",
      "ninja                     1.10.0           py36hfd86e86_0  \n",
      "notebook                  6.1.3            py36h9f0ad1d_0    conda-forge\n",
      "numpy                     1.19.1           py36hbc911f0_0  \n",
      "numpy-base                1.19.1           py36hfa32c7d_0  \n",
      "olefile                   0.46                     py36_0  \n",
      "opencv-python             4.1.2.30                 pypi_0    pypi\n",
      "openh264                  1.8.0             hdbcaa40_1000    conda-forge\n",
      "openssl                   1.1.1g               h7b6447c_0    anaconda\n",
      "packaging                 20.4               pyh9f0ad1d_0    conda-forge\n",
      "pandoc                    2.10.1               h516909a_0    conda-forge\n",
      "pandocfilters             1.4.2                      py_1    conda-forge\n",
      "parso                     0.7.1              pyh9f0ad1d_0    conda-forge\n",
      "pexpect                   4.8.0            py36h9f0ad1d_1    conda-forge\n",
      "pickleshare               0.7.5           py36h9f0ad1d_1001    conda-forge\n",
      "pillow                    7.0.0                    pypi_0    pypi\n",
      "pip                       20.2.2                   py36_0  \n",
      "prometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge\n",
      "prompt-toolkit            3.0.6                      py_0    conda-forge\n",
      "ptyprocess                0.6.0                   py_1001    conda-forge\n",
      "pycparser                 2.20               pyh9f0ad1d_2    conda-forge\n",
      "pygments                  2.6.1                      py_0    conda-forge\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\n",
      "pyrsistent                0.16.0           py36h8c4c3a4_0    conda-forge\n",
      "python                    3.6.7                h0371630_0  \n",
      "python-dateutil           2.8.1                      py_0    conda-forge\n",
      "python_abi                3.6                     1_cp36m    conda-forge\n",
      "pytorch                   1.4.0           py3.6_cuda10.1.243_cudnn7.6.3_0    pytorch\n",
      "pywavelets                1.1.1                    pypi_0    pypi\n",
      "pyzmq                     19.0.2           py36h9947dbf_0    conda-forge\n",
      "readline                  7.0                  h7b6447c_5  \n",
      "scikit-image              0.16.2                   pypi_0    pypi\n",
      "scipy                     1.2.1                    pypi_0    pypi\n",
      "send2trash                1.5.0                      py_0    conda-forge\n",
      "setuptools                49.6.0                   py36_0  \n",
      "six                       1.15.0                     py_0  \n",
      "sqlite                    3.32.3               h62c20be_0  \n",
      "terminado                 0.8.3            py36h9f0ad1d_1    conda-forge\n",
      "testpath                  0.4.4                      py_0    conda-forge\n",
      "tk                        8.6.10               hbc83047_0  \n",
      "torchvision               0.5.0                py36_cu101    pytorch\n",
      "tornado                   6.0.4            py36h8c4c3a4_1    conda-forge\n",
      "tqdm                      4.43.0                   pypi_0    pypi\n",
      "traitlets                 4.3.3            py36h9f0ad1d_1    conda-forge\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_1    conda-forge\n",
      "webencodings              0.5.1                      py_1    conda-forge\n",
      "wheel                     0.34.2                   py36_0  \n",
      "x264                      1!152.20180806       h7b6447c_0    anaconda\n",
      "xz                        5.2.5                h7b6447c_0  \n",
      "zeromq                    4.3.2                he1b5a44_3    conda-forge\n",
      "zipp                      3.1.0                      py_0    conda-forge\n",
      "zlib                      1.2.11               h7b6447c_3  \n",
      "zstd                      1.4.5                h9ceee32_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "# import torch\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Images using the main.py script with arg: --mode align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/male', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='align', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/male', print_every=10, randcrop_prob=0.5, ref_dir='assets/representative/celeba_hq/ref', result_dir='expr/results', resume_iter=0, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='assets/representative/celeba_hq/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "File name - .ipynb_checkpoints - is skipped!\n",
      "/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Saved the aligned image to custom_male.jpg...\n",
      "Saved the aligned image to master_avg_face.jpg...\n",
      "Saved the aligned image to my_pic.png...\n"
     ]
    }
   ],
   "source": [
    "# !python main.py --mode align \\\n",
    "#                --inp_dir assets/representative/custom/male \\\n",
    "#                --out_dir assets/representative/celeba_hq/src/male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='eval', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='my_experiment/ref', result_dir='my_experiment/results', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='my_experiment/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
      "Calculating evaluation metrics...\n",
      "Number of domains: 2\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Generating images and calculating LPIPS for male2female...\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /home/hamdi_ug/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n",
      "\n",
      "  0%|                                                | 0.00/233M [00:00<?, ?B/s]\u001b[A\n",
      "  0%|                                        | 112k/233M [00:00<03:56, 1.03MB/s]\u001b[A\n",
      "  0%|                                        | 480k/233M [00:00<03:13, 1.26MB/s]\u001b[A\n",
      "  1%|▎                                      | 1.78M/233M [00:00<02:19, 1.73MB/s]\u001b[A\n",
      "  2%|▊                                      | 4.60M/233M [00:00<01:39, 2.42MB/s]\u001b[A\n",
      "  3%|█▎                                     | 7.53M/233M [00:00<01:10, 3.34MB/s]\u001b[A\n",
      "  4%|█▌                                     | 9.34M/233M [00:01<01:16, 3.05MB/s]\u001b[A\n",
      "  5%|█▉                                     | 11.9M/233M [00:01<00:55, 4.16MB/s]\u001b[A\n",
      "  6%|██▎                                    | 13.5M/233M [00:01<00:44, 5.14MB/s]\u001b[A\n",
      "  7%|██▋                                    | 16.1M/233M [00:01<00:33, 6.79MB/s]\u001b[A\n",
      "  8%|███                                    | 18.0M/233M [00:01<00:27, 8.31MB/s]\u001b[A\n",
      " 10%|███▋                                   | 22.2M/233M [00:01<00:20, 10.7MB/s]\u001b[A\n",
      " 11%|████▏                                  | 25.2M/233M [00:02<00:16, 13.2MB/s]\u001b[A\n",
      " 13%|█████                                  | 30.6M/233M [00:02<00:12, 17.1MB/s]\u001b[A\n",
      " 15%|█████▊                                 | 34.5M/233M [00:02<00:10, 20.6MB/s]\u001b[A\n",
      " 16%|██████▎                                | 37.9M/233M [00:02<00:09, 20.9MB/s]\u001b[A\n",
      " 18%|██████▊                                | 40.9M/233M [00:02<00:09, 21.8MB/s]\u001b[A\n",
      " 19%|███████▍                               | 44.1M/233M [00:02<00:08, 22.1MB/s]\u001b[A\n",
      " 21%|████████                               | 48.4M/233M [00:02<00:07, 26.0MB/s]\u001b[A\n",
      " 22%|████████▌                              | 51.5M/233M [00:02<00:08, 23.7MB/s]\u001b[A\n",
      " 23%|█████████                              | 54.2M/233M [00:03<00:10, 17.7MB/s]\u001b[A\n",
      " 24%|█████████▍                             | 56.5M/233M [00:03<00:10, 18.4MB/s]\u001b[A\n",
      " 25%|█████████▉                             | 59.3M/233M [00:03<00:08, 20.8MB/s]\u001b[A\n",
      " 27%|██████████▌                            | 63.0M/233M [00:03<00:07, 24.1MB/s]\u001b[A\n",
      " 28%|██████████▉                            | 65.7M/233M [00:03<00:06, 25.1MB/s]\u001b[A\n",
      " 29%|███████████▍                           | 68.4M/233M [00:03<00:07, 23.4MB/s]\u001b[A\n",
      " 31%|███████████▉                           | 71.7M/233M [00:03<00:07, 24.0MB/s]\u001b[A\n",
      " 33%|████████████▋                          | 76.2M/233M [00:03<00:05, 28.2MB/s]\u001b[A\n",
      " 34%|█████████████▎                         | 79.9M/233M [00:04<00:05, 28.5MB/s]\u001b[A\n",
      " 36%|█████████████▉                         | 83.1M/233M [00:04<00:05, 28.8MB/s]\u001b[A\n",
      " 37%|██████████████▌                        | 86.8M/233M [00:04<00:04, 31.1MB/s]\u001b[A\n",
      " 39%|███████████████                        | 89.9M/233M [00:04<00:05, 26.7MB/s]\u001b[A\n",
      " 40%|███████████████▌                       | 93.2M/233M [00:04<00:05, 28.5MB/s]\u001b[A\n",
      " 41%|████████████████                       | 96.1M/233M [00:04<00:05, 27.8MB/s]\u001b[A\n",
      " 42%|████████████████▌                      | 98.9M/233M [00:04<00:05, 24.7MB/s]\u001b[A\n",
      " 44%|█████████████████▍                      | 102M/233M [00:04<00:05, 26.1MB/s]\u001b[A\n",
      " 45%|█████████████████▉                      | 104M/233M [00:05<00:05, 25.3MB/s]\u001b[A\n",
      " 46%|██████████████████▍                     | 107M/233M [00:05<00:04, 26.5MB/s]\u001b[A\n",
      " 47%|██████████████████▊                     | 110M/233M [00:05<00:04, 25.8MB/s]\u001b[A\n",
      " 48%|███████████████████▎                    | 112M/233M [00:05<00:05, 25.2MB/s]\u001b[A\n",
      " 49%|███████████████████▋                    | 115M/233M [00:05<00:04, 25.7MB/s]\u001b[A\n",
      " 50%|████████████████████▏                   | 118M/233M [00:05<00:05, 22.3MB/s]\u001b[A\n",
      " 51%|████████████████████▌                   | 120M/233M [00:05<00:05, 22.3MB/s]\u001b[A\n",
      " 52%|████████████████████▉                   | 122M/233M [00:05<00:05, 22.4MB/s]\u001b[A\n",
      " 54%|█████████████████████▋                  | 126M/233M [00:05<00:04, 26.0MB/s]\u001b[A\n",
      " 55%|██████████████████████                  | 129M/233M [00:06<00:04, 24.4MB/s]\u001b[A\n",
      " 56%|██████████████████████▌                 | 131M/233M [00:06<00:04, 22.2MB/s]\u001b[A\n",
      " 58%|███████████████████████▏                | 135M/233M [00:06<00:04, 25.0MB/s]\u001b[A\n",
      " 59%|███████████████████████▋                | 138M/233M [00:06<00:03, 26.5MB/s]\u001b[A\n",
      " 60%|████████████████████████                | 140M/233M [00:06<00:04, 22.9MB/s]\u001b[A\n",
      " 61%|████████████████████████▌               | 143M/233M [00:06<00:04, 22.8MB/s]\u001b[A\n",
      " 63%|█████████████████████████▏              | 147M/233M [00:06<00:03, 22.7MB/s]\u001b[A\n",
      " 64%|█████████████████████████▋              | 150M/233M [00:07<00:03, 24.2MB/s]\u001b[A\n",
      " 66%|██████████████████████████▎             | 153M/233M [00:07<00:03, 26.9MB/s]\u001b[A\n",
      " 67%|██████████████████████████▊             | 156M/233M [00:07<00:02, 28.0MB/s]\u001b[A\n",
      " 68%|███████████████████████████▎            | 159M/233M [00:07<00:03, 23.6MB/s]\u001b[A\n",
      " 70%|███████████████████████████▉            | 163M/233M [00:07<00:02, 26.7MB/s]\u001b[A\n",
      " 71%|████████████████████████████▍           | 165M/233M [00:07<00:02, 25.9MB/s]\u001b[A\n",
      " 72%|████████████████████████████▊           | 168M/233M [00:07<00:02, 23.6MB/s]\u001b[A\n",
      " 73%|█████████████████████████████▍          | 171M/233M [00:07<00:02, 25.8MB/s]\u001b[A\n",
      " 75%|█████████████████████████████▊          | 174M/233M [00:07<00:02, 26.3MB/s]\u001b[A\n",
      " 76%|██████████████████████████████▎         | 177M/233M [00:08<00:02, 25.1MB/s]\u001b[A\n",
      " 77%|██████████████████████████████▋         | 179M/233M [00:08<00:02, 23.5MB/s]\u001b[A\n",
      " 78%|███████████████████████████████▏        | 181M/233M [00:08<00:02, 22.5MB/s]\u001b[A\n",
      " 79%|███████████████████████████████▋        | 185M/233M [00:08<00:02, 25.2MB/s]\u001b[A\n",
      " 80%|████████████████████████████████▏       | 187M/233M [00:08<00:02, 22.4MB/s]\u001b[A\n",
      " 81%|████████████████████████████████▌       | 190M/233M [00:08<00:02, 20.0MB/s]\u001b[A\n",
      " 82%|████████████████████████████████▉       | 192M/233M [00:08<00:02, 20.1MB/s]\u001b[A\n",
      " 84%|█████████████████████████████████▍      | 195M/233M [00:08<00:01, 21.5MB/s]\u001b[A\n",
      " 85%|██████████████████████████████████▏     | 199M/233M [00:09<00:01, 25.3MB/s]\u001b[A\n",
      " 87%|██████████████████████████████████▌     | 202M/233M [00:09<00:01, 25.0MB/s]\u001b[A\n",
      " 88%|███████████████████████████████████     | 204M/233M [00:09<00:01, 24.4MB/s]\u001b[A\n",
      " 89%|███████████████████████████████████▌    | 207M/233M [00:09<00:01, 25.1MB/s]\u001b[A\n",
      " 90%|███████████████████████████████████▉    | 210M/233M [00:10<00:05, 4.89MB/s]\u001b[A\n",
      " 92%|████████████████████████████████████▋   | 213M/233M [00:11<00:03, 6.65MB/s]\u001b[A\n",
      " 93%|█████████████████████████████████████   | 216M/233M [00:11<00:02, 8.07MB/s]\u001b[A\n",
      " 94%|█████████████████████████████████████▌  | 219M/233M [00:11<00:01, 9.86MB/s]\u001b[A\n",
      " 95%|██████████████████████████████████████  | 222M/233M [00:11<00:00, 12.2MB/s]\u001b[A\n",
      " 97%|██████████████████████████████████████▋ | 225M/233M [00:11<00:00, 14.5MB/s]\u001b[A\n",
      " 98%|███████████████████████████████████████▎| 229M/233M [00:11<00:00, 18.1MB/s]\u001b[A\n",
      "100%|████████████████████████████████████████| 233M/233M [00:11<00:00, 20.6MB/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 32/32 [14:22<00:00, 26.94s/it]\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Generating images and calculating LPIPS for female2male...\n",
      "100%|███████████████████████████████████████████| 32/32 [13:50<00:00, 25.96s/it]\n",
      "Calculating FID for all tasks...\n",
      "Calculating FID for male2female...\n",
      "Calculating FID given paths data/celeba_hq/train/female and expr/eval/male2female...\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /home/hamdi_ug/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
      "100%|████████████████████████████████████████| 104M/104M [00:03<00:00, 32.1MB/s]\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "100%|█████████████████████████████████████████| 561/561 [03:54<00:00,  2.39it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [00:30<00:00, 10.28it/s]\n",
      "Calculating FID for female2male...\n",
      "Calculating FID given paths data/celeba_hq/train/male and expr/eval/female2male...\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "100%|█████████████████████████████████████████| 315/315 [01:13<00:00,  4.27it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [00:22<00:00, 13.90it/s]\n",
      "Calculating evaluation metrics...\n",
      "Number of domains: 2\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Generating images and calculating LPIPS for male2female...\n",
      "100%|███████████████████████████████████████████| 32/32 [14:08<00:00, 26.52s/it]\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Preparing DataLoader for the evaluation phase...\n",
      "Generating images and calculating LPIPS for female2male...\n",
      "  3%|█▍                                          | 1/32 [00:28<14:29, 28.06s/it]^C\n"
     ]
    }
   ],
   "source": [
    "# !python main.py --mode eval --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
    "#                 --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
    "#                 --result_dir my_experiment/results \\\n",
    "#                 --src_dir my_experiment/src \\\n",
    "#                 --ref_dir my_experiment/ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdirs(dname):\n",
    "    return [d for d in os.listdir(dname)\n",
    "            if os.path.isdir(os.path.join(dname, d)) and d != '.ipynb_checkpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', 'female']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdirs('./my_experiment/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='my_experiment/ref', result_dir='my_experiment/results', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='my_experiment/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
      "Working on my_experiment/results/reference.jpg...\n",
      "/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [96,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [97,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [98,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [99,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [100,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [102,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [103,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [104,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [106,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [108,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [110,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [111,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [112,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [114,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [115,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [116,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [117,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [118,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [119,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [120,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [121,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [122,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [123,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [124,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [125,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [127,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [65,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [66,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [67,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [68,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [69,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [70,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [71,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [73,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [75,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [76,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [77,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [78,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [79,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [81,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [83,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [84,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [86,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [87,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [88,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [89,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [90,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [91,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [92,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [93,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1579027003190/work/aten/src/ATen/native/cuda/IndexKernel.cu:60: lambda [](int)->auto::operator()(int)->auto: block: [0,0,0], thread: [95,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 182, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 73, in main\n",
      "    solver.sample(loaders)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/solver.py\", line 185, in sample\n",
      "    utils.translate_using_reference(nets_ema, args, src.x, ref.x, ref.y, fname)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/utils.py\", line 112, in translate_using_reference\n",
      "    x_fake = nets.generator(x_src, s_ref, masks=masks)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/model.py\", line 174, in forward\n",
      "    x = self.from_rgb(x)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 345, in forward\n",
      "    return self.conv2d_forward(input, self.weight)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 342, in conv2d_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n"
     ]
    }
   ],
   "source": [
    "# !python main.py --mode sample --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
    "#                 --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
    "#                 --result_dir my_experiment/results \\\n",
    "#                 --src_dir my_experiment/src \\\n",
    "#                 --ref_dir my_experiment/ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='my_experiment/ref', result_dir='my_experiment/results', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='my_experiment/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
      "Working on my_experiment/results/reference.jpg...\n",
      "/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 182, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 73, in main\n",
      "    solver.sample(loaders)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/solver.py\", line 185, in sample\n",
      "    utils.translate_using_reference(nets_ema, args, src.x, ref.x, ref.y, fname)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/utils.py\", line 112, in translate_using_reference\n",
      "    x_fake = nets.generator(x_src, s_ref, masks=masks)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/model.py\", line 179, in forward\n",
      "    x = block(x)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/model.py\", line 63, in forward\n",
      "    x = self._shortcut(x) + self._residual(x)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/model.py\", line 51, in _residual\n",
      "    x = self.norm1(x)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/instancenorm.py\", line 57, in forward\n",
      "    self.training or not self.track_running_stats, self.momentum, self.eps)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py\", line 2038, in instance_norm\n",
      "    use_input_stats, momentum, eps, torch.backends.cudnn.enabled\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [96,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [97,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [98,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [99,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [100,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [101,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [102,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [103,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [104,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [105,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [106,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [107,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [108,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [109,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [110,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [111,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [112,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [113,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [114,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [115,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [116,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [117,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [118,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [119,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [120,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [121,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [122,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [123,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [124,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [125,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [126,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [127,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [65,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [66,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [67,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [68,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [69,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [70,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [71,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [72,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [73,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [74,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [75,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [76,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [77,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [78,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [79,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [80,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [81,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [82,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [83,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [84,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [85,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [86,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [87,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [88,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [89,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [90,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [91,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [92,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [93,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [94,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/cuda/IndexKernel.cu:84: operator(): block: [0,0,0], thread: [95,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    }
   ],
   "source": [
    "# !python main.py --mode sample --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
    "#                 --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
    "#                 --result_dir my_experiment/results \\\n",
    "#                 --src_dir my_experiment/src \\\n",
    "#                 --ref_dir my_experiment/ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With average faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='my_experiment/ref', result_dir='my_experiment/results', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='my_experiment/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
      "InputFetcher._fetch_inputs method called..\n",
      "self.LOADER: <torch.utils.data.dataloader.DataLoader object at 0x7fc880342e48>\n",
      "InputFetcher._fetch_inputs method called..\n",
      "self.LOADER: <torch.utils.data.dataloader.DataLoader object at 0x7fc8802e3208>\n",
      "Working on my_experiment/results/reference_avg.jpg...\n",
      "REF_y: tensor([1, 1, 2, 2], device='cuda:0') ----> tensor([0, 0, 1, 1], device='cuda:0')\n",
      "NCHW: 2 3 256 256\n",
      "/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "len(MASKS): 2 MASKS[0].SHAPE torch.Size([2, 1, 256, 256])\n",
      "\n",
      "X_REF.SHAPE: torch.Size([4, 3, 256, 256]) Y_REF.SHAPE: torch.Size([4])\n",
      "X.shape, Y.shape and Y:\n",
      "torch.Size([4, 3, 256, 256]) torch.Size([4]) tensor([0, 0, 1, 1], device='cuda:0')\n",
      "H.shape before: torch.Size([4, 512, 1, 1])\n",
      "H.shape after: torch.Size([4, 512])\n",
      "len(out) before: 2\n",
      "out.shape after: torch.Size([4, 2, 64])\n",
      "OUT: tensor([[[ 1.1713, -1.1371,  0.2181, -0.2989, -0.7462,  0.3311,  0.5409,\n",
      "           1.6859,  1.7946, -0.4707, -1.5976, -1.6116, -0.8940,  0.8856,\n",
      "           0.1836, -0.4243,  1.5599,  0.0772, -0.8860,  1.0079,  0.5985,\n",
      "          -1.1520,  0.9832, -1.3237,  0.4058,  0.1356,  1.1079, -0.8748,\n",
      "           1.6796, -0.5946, -0.6884,  0.5382, -1.3920, -0.8834,  1.6290,\n",
      "          -0.6876,  0.0090,  1.6941, -0.4298,  0.1530, -2.2129,  0.9818,\n",
      "          -1.2147, -1.1813, -0.5949, -0.4926, -0.9399, -0.3763,  0.4755,\n",
      "          -2.0352, -1.7954,  0.1015,  0.5432,  0.1582,  0.6301,  0.9467,\n",
      "          -1.4342, -1.3404,  1.9331, -1.5649,  0.1566,  1.0164, -1.9589,\n",
      "          -0.4186],\n",
      "         [-0.3219, -1.4319, -0.3994,  1.4013, -0.0781,  0.4606,  0.9882,\n",
      "           1.1066, -1.8467,  0.1585,  1.7096, -1.6057,  0.8242,  0.2532,\n",
      "           0.6031,  0.3341, -0.7456,  0.7144,  0.7835,  2.4832, -0.4540,\n",
      "           0.4331, -0.7016,  0.9983,  0.3759,  0.7094, -1.9019, -0.2641,\n",
      "          -0.6796, -0.9898,  0.5418,  0.0674, -0.7560,  0.6959, -0.9773,\n",
      "           0.6438, -0.1610, -0.8088,  0.0536,  0.3052,  0.2063,  0.0106,\n",
      "           0.2880,  0.9206,  0.5301, -0.9837,  0.1734, -1.1604,  0.1792,\n",
      "          -0.7033, -1.4580, -1.1315, -0.8609,  1.1123,  0.2560, -0.4325,\n",
      "          -1.5310,  1.6257, -0.2232,  0.3325,  2.1275, -0.0079, -1.5997,\n",
      "           1.2711]],\n",
      "\n",
      "        [[ 0.6776, -1.5430, -0.7164,  0.2152,  0.5670, -1.6632,  1.1221,\n",
      "           3.2155,  0.3563, -0.9629, -3.1680, -1.1736, -1.0794,  1.3196,\n",
      "           0.8001, -0.3717,  2.3224,  0.8890, -1.9476,  0.9115,  2.0509,\n",
      "          -1.6646, -0.3100, -1.8459,  0.5882,  0.6083,  1.1057, -1.9918,\n",
      "           2.4824, -1.4759, -1.6313, -0.7058, -1.3881, -0.6820,  2.6467,\n",
      "          -0.0302,  0.0115,  0.2429, -1.4044, -0.7438, -1.9869,  2.4550,\n",
      "          -1.7669,  0.6421, -0.4309, -0.9263,  0.7266,  0.8827,  0.5264,\n",
      "          -2.0512, -2.3029, -1.0586, -0.4346, -0.5966,  1.1862,  2.0978,\n",
      "          -0.8335, -1.0470,  1.8706, -0.2745,  0.5227,  0.0829, -1.5875,\n",
      "          -2.5666],\n",
      "         [-2.1465, -1.6285, -2.2838,  0.1723, -1.5472, -1.2965,  1.1415,\n",
      "           2.6549, -4.5875,  3.4311,  2.2844, -1.9190,  1.7729,  1.2190,\n",
      "          -1.4146,  0.3119, -1.2595,  1.6131, -0.7064,  3.0300, -3.6302,\n",
      "           0.2127, -1.7338,  0.1056,  1.1454, -0.5467, -2.1192, -1.8119,\n",
      "           0.1001, -1.1012,  0.8106, -3.1949,  0.3589,  1.2760, -1.6215,\n",
      "           0.9604,  2.8863, -2.6730, -0.6955, -0.0778, -0.7549, -2.1088,\n",
      "           0.4089,  1.3288,  1.2488,  0.8108, -0.2858, -0.9061, -0.2689,\n",
      "          -3.1531, -5.3869, -1.1870, -2.2800,  2.1812,  2.1731,  2.0622,\n",
      "          -5.7566,  0.2877,  0.8445,  2.7953,  2.8429, -1.6007, -3.3252,\n",
      "           1.6322]],\n",
      "\n",
      "        [[ 0.6776, -1.5430, -0.7164,  0.2152,  0.5670, -1.6632,  1.1221,\n",
      "           3.2155,  0.3563, -0.9629, -3.1680, -1.1736, -1.0794,  1.3196,\n",
      "           0.8001, -0.3717,  2.3224,  0.8890, -1.9476,  0.9115,  2.0509,\n",
      "          -1.6646, -0.3100, -1.8459,  0.5882,  0.6083,  1.1057, -1.9918,\n",
      "           2.4824, -1.4759, -1.6313, -0.7058, -1.3881, -0.6820,  2.6467,\n",
      "          -0.0302,  0.0115,  0.2429, -1.4044, -0.7438, -1.9869,  2.4550,\n",
      "          -1.7669,  0.6421, -0.4309, -0.9263,  0.7266,  0.8827,  0.5264,\n",
      "          -2.0512, -2.3029, -1.0586, -0.4346, -0.5966,  1.1862,  2.0978,\n",
      "          -0.8335, -1.0470,  1.8706, -0.2745,  0.5227,  0.0829, -1.5875,\n",
      "          -2.5666],\n",
      "         [-2.1465, -1.6285, -2.2838,  0.1723, -1.5472, -1.2965,  1.1415,\n",
      "           2.6549, -4.5875,  3.4311,  2.2844, -1.9190,  1.7729,  1.2190,\n",
      "          -1.4146,  0.3119, -1.2595,  1.6131, -0.7064,  3.0300, -3.6302,\n",
      "           0.2127, -1.7338,  0.1056,  1.1454, -0.5467, -2.1192, -1.8119,\n",
      "           0.1001, -1.1012,  0.8106, -3.1949,  0.3589,  1.2760, -1.6215,\n",
      "           0.9604,  2.8863, -2.6730, -0.6955, -0.0778, -0.7549, -2.1088,\n",
      "           0.4089,  1.3288,  1.2488,  0.8108, -0.2858, -0.9061, -0.2689,\n",
      "          -3.1531, -5.3869, -1.1870, -2.2800,  2.1812,  2.1731,  2.0622,\n",
      "          -5.7566,  0.2877,  0.8445,  2.7953,  2.8429, -1.6007, -3.3252,\n",
      "           1.6322]],\n",
      "\n",
      "        [[ 0.9720, -1.1535,  1.4238, -0.8048,  0.6904,  0.2686,  0.8107,\n",
      "           2.7219,  1.8601, -0.1293, -0.4463, -0.5425, -0.3317,  0.1070,\n",
      "           0.0539, -0.8237,  1.4947, -0.2818, -1.2205,  0.5682,  1.2194,\n",
      "          -0.6325,  0.1871, -0.9434,  0.0213,  0.6913,  0.0730, -1.2544,\n",
      "           1.7644,  0.4236, -0.2921,  0.8333, -2.5376, -2.4676,  1.5539,\n",
      "           0.9751,  0.3687,  1.5679,  0.0484,  0.1946, -1.6904,  0.8383,\n",
      "          -1.2427, -0.7383, -2.1356, -0.2745,  1.1918,  0.5939, -0.1022,\n",
      "          -2.1235, -0.7148, -1.9290, -0.1570,  0.6251,  0.8141,  2.4029,\n",
      "          -0.5638, -1.5020,  2.2096, -0.1035,  1.4177,  0.3899, -1.4984,\n",
      "          -2.5245],\n",
      "         [-1.5859, -0.8443,  0.0596, -0.2741, -0.9314,  0.7997,  0.9188,\n",
      "           2.2584, -2.5288,  0.2803,  2.2092, -0.7454,  1.1605,  0.6373,\n",
      "           0.5833,  1.1958, -0.3551,  1.5484,  0.4268,  2.9004, -1.1209,\n",
      "          -0.5285, -1.7533,  0.3542,  0.4167,  0.9998, -3.4420, -0.3611,\n",
      "          -1.1645, -2.0651,  1.1998, -0.0554, -0.7389,  0.2662, -0.6094,\n",
      "           0.2746,  0.2858, -0.9194, -1.2720,  0.3066, -0.2065, -0.7954,\n",
      "           0.9751,  1.2617, -0.1461, -0.6361, -0.6287, -0.7954, -0.4421,\n",
      "          -2.1276, -3.2984, -1.7640, -2.0282,  1.2132,  1.4546, -0.4907,\n",
      "          -1.2654,  2.4529, -0.3942,  0.7888,  2.9713, -0.0334, -2.6268,\n",
      "           2.2695]]], device='cuda:0')\n",
      "IDX: tensor([0, 1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "!python main.py --mode sample --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
    "                --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
    "                --result_dir my_experiment/results \\\n",
    "                --src_dir my_experiment/src \\\n",
    "                --ref_dir my_experiment/ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** np.asarray(y) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First successful execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='my_experiment/ref', result_dir='my_experiment/results', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='my_experiment/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
      "self.LOADER: <torch.utils.data.dataloader.DataLoader object at 0x7f8e900cfe80>\n",
      "x::\n",
      " tensor([[[[-0.8902, -0.8667, -0.8431,  ..., -0.7412, -0.7098, -0.6706],\n",
      "          [-0.8902, -0.8667, -0.8431,  ..., -0.7647, -0.7255, -0.6863],\n",
      "          [-0.8824, -0.8667, -0.8353,  ..., -0.7882, -0.7490, -0.7176],\n",
      "          ...,\n",
      "          [ 0.3882,  0.3804,  0.4824,  ...,  0.2392,  0.3412,  0.4510],\n",
      "          [ 0.4118,  0.4039,  0.4745,  ...,  0.2157,  0.3490,  0.4431],\n",
      "          [ 0.5137,  0.4039,  0.5608,  ...,  0.2235,  0.3490,  0.4431]],\n",
      "\n",
      "         [[-0.9137, -0.9059, -0.8980,  ..., -0.8667, -0.8667, -0.8510],\n",
      "          [-0.9137, -0.9059, -0.8980,  ..., -0.8824, -0.8745, -0.8667],\n",
      "          [-0.9059, -0.9059, -0.8902,  ..., -0.8902, -0.8824, -0.8745],\n",
      "          ...,\n",
      "          [ 0.0745,  0.0588,  0.1686,  ..., -0.0745,  0.0275,  0.1686],\n",
      "          [ 0.1059,  0.0980,  0.1608,  ..., -0.1216,  0.0196,  0.1529],\n",
      "          [ 0.2549,  0.1373,  0.3020,  ..., -0.1294,  0.0039,  0.1373]],\n",
      "\n",
      "         [[-0.9686, -0.9529, -0.9451,  ..., -0.9765, -0.9843, -0.9765],\n",
      "          [-0.9686, -0.9529, -0.9451,  ..., -0.9843, -0.9843, -0.9765],\n",
      "          [-0.9608, -0.9529, -0.9373,  ..., -0.9765, -0.9765, -0.9765],\n",
      "          ...,\n",
      "          [-0.0980, -0.1137, -0.0118,  ..., -0.4510, -0.3569, -0.2000],\n",
      "          [-0.0431, -0.0510,  0.0196,  ..., -0.4980, -0.3882, -0.2549],\n",
      "          [ 0.1216,  0.0039,  0.1608,  ..., -0.5059, -0.4196, -0.2863]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7490,  0.7333,  0.7098,  ...,  0.8980,  0.8980,  0.8980],\n",
      "          [ 0.7490,  0.7490,  0.7490,  ...,  0.8980,  0.8980,  0.8980],\n",
      "          [ 0.7569,  0.7490,  0.7490,  ...,  0.8980,  0.8980,  0.8980],\n",
      "          ...,\n",
      "          [-0.6235, -0.5608, -0.5765,  ..., -0.4039, -0.6706, -0.8353],\n",
      "          [-0.5765, -0.5294, -0.5529,  ..., -0.5216, -0.7098, -0.8275],\n",
      "          [-0.5765, -0.5922, -0.4510,  ..., -0.4902, -0.6471, -0.7961]],\n",
      "\n",
      "         [[ 0.7804,  0.7647,  0.7412,  ...,  0.9373,  0.9373,  0.9373],\n",
      "          [ 0.7804,  0.7804,  0.7804,  ...,  0.9373,  0.9373,  0.9373],\n",
      "          [ 0.7882,  0.7804,  0.7804,  ...,  0.9373,  0.9373,  0.9373],\n",
      "          ...,\n",
      "          [-0.5608, -0.5059, -0.5451,  ..., -0.3725, -0.6157, -0.7804],\n",
      "          [-0.5373, -0.4902, -0.5294,  ..., -0.4902, -0.6549, -0.7725],\n",
      "          [-0.5294, -0.5608, -0.4196,  ..., -0.4510, -0.5922, -0.7333]],\n",
      "\n",
      "         [[ 0.8510,  0.8353,  0.8118,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 0.8510,  0.8510,  0.8510,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 0.8588,  0.8510,  0.8510,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          ...,\n",
      "          [-0.4667, -0.4275, -0.4902,  ..., -0.3098, -0.5529, -0.7255],\n",
      "          [-0.4431, -0.4196, -0.4824,  ..., -0.4196, -0.5922, -0.7098],\n",
      "          [-0.4353, -0.4745, -0.3725,  ..., -0.3725, -0.5216, -0.6784]]]]) y:: tensor([1, 2])\n",
      "self.LOADER: <torch.utils.data.dataloader.DataLoader object at 0x7f8e7c0e5278>\n",
      "x::\n",
      " tensor([[[[-0.6863, -0.7098, -0.7255,  ..., -0.7882, -0.7804, -0.7882],\n",
      "          [-0.6863, -0.7098, -0.7255,  ..., -0.7882, -0.7882, -0.7961],\n",
      "          [-0.6863, -0.7098, -0.7255,  ..., -0.7882, -0.7804, -0.7961],\n",
      "          ...,\n",
      "          [-0.8275, -0.8353, -0.8431,  ...,  0.7725,  0.8588,  0.8824],\n",
      "          [-0.8275, -0.8275, -0.8275,  ...,  0.8431,  0.8745,  0.8745],\n",
      "          [-0.8196, -0.8118, -0.8196,  ...,  0.8353,  0.8510,  0.8667]],\n",
      "\n",
      "         [[-0.8196, -0.8353, -0.8353,  ..., -0.7961, -0.7882, -0.7961],\n",
      "          [-0.8196, -0.8353, -0.8353,  ..., -0.7961, -0.7961, -0.8039],\n",
      "          [-0.8196, -0.8353, -0.8353,  ..., -0.7961, -0.7882, -0.8039],\n",
      "          ...,\n",
      "          [-0.8667, -0.8745, -0.8824,  ...,  0.3961,  0.6392,  0.7020],\n",
      "          [-0.8667, -0.8667, -0.8667,  ...,  0.5451,  0.7098,  0.7020],\n",
      "          [-0.8588, -0.8510, -0.8588,  ...,  0.5843,  0.7255,  0.7020]],\n",
      "\n",
      "         [[-0.8824, -0.8902, -0.8745,  ..., -0.8275, -0.8196, -0.8275],\n",
      "          [-0.8824, -0.8902, -0.8745,  ..., -0.8275, -0.8275, -0.8353],\n",
      "          [-0.8824, -0.8902, -0.8745,  ..., -0.8275, -0.8196, -0.8353],\n",
      "          ...,\n",
      "          [-0.8980, -0.9059, -0.9137,  ...,  0.0980,  0.4667,  0.5529],\n",
      "          [-0.8980, -0.8980, -0.8980,  ...,  0.3098,  0.5765,  0.5608],\n",
      "          [-0.8902, -0.8824, -0.8902,  ...,  0.3961,  0.6235,  0.5686]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8118,  0.8275,  0.8196,  ...,  0.7882,  0.7961,  0.7961],\n",
      "          [ 0.8118,  0.8275,  0.8196,  ...,  0.8039,  0.7961,  0.7961],\n",
      "          [ 0.8118,  0.8275,  0.8275,  ...,  0.8039,  0.8039,  0.8039],\n",
      "          ...,\n",
      "          [ 0.5451,  0.5451,  0.5216,  ..., -0.7804, -0.7647, -0.7647],\n",
      "          [ 0.5059,  0.5294,  0.5451,  ..., -0.7725, -0.7725, -0.7569],\n",
      "          [ 0.4667,  0.4980,  0.5294,  ..., -0.7725, -0.7725, -0.7569]],\n",
      "\n",
      "         [[ 0.8196,  0.8353,  0.8275,  ...,  0.7882,  0.7961,  0.7961],\n",
      "          [ 0.8196,  0.8353,  0.8275,  ...,  0.8039,  0.7961,  0.7961],\n",
      "          [ 0.8196,  0.8353,  0.8353,  ...,  0.8039,  0.8039,  0.8039],\n",
      "          ...,\n",
      "          [ 0.5529,  0.5529,  0.5294,  ..., -0.8118, -0.7961, -0.7961],\n",
      "          [ 0.5137,  0.5373,  0.5529,  ..., -0.8039, -0.8039, -0.7882],\n",
      "          [ 0.4745,  0.5059,  0.5373,  ..., -0.8039, -0.8039, -0.7882]],\n",
      "\n",
      "         [[ 0.8510,  0.8667,  0.8588,  ...,  0.8039,  0.8118,  0.8118],\n",
      "          [ 0.8510,  0.8667,  0.8588,  ...,  0.8196,  0.8118,  0.8118],\n",
      "          [ 0.8510,  0.8667,  0.8667,  ...,  0.8196,  0.8196,  0.8196],\n",
      "          ...,\n",
      "          [ 0.5922,  0.5922,  0.5686,  ..., -0.8353, -0.8196, -0.8196],\n",
      "          [ 0.5529,  0.5765,  0.5922,  ..., -0.8275, -0.8275, -0.8118],\n",
      "          [ 0.5137,  0.5451,  0.5765,  ..., -0.8275, -0.8275, -0.8118]]]]) y:: tensor([1, 2])\n",
      "Working on my_experiment/results/reference.jpg...\n",
      "REF_y: tensor([1, 2]) ----> tensor([0, 1])\n",
      "NCHW: 2 3 256 256\n",
      "/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "len(MASKS): 2 MASKS[0].SHAPE torch.Size([2, 1, 256, 256])\n",
      "MASKS:\n",
      " (tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]))\n",
      "\n",
      "X_REF.SHAPE: torch.Size([2, 3, 256, 256]) Y_REF.SHAPE: torch.Size([2])\n",
      "x_ref:\n",
      " tensor([[[[-0.6863, -0.7098, -0.7255,  ..., -0.7882, -0.7804, -0.7882],\n",
      "          [-0.6863, -0.7098, -0.7255,  ..., -0.7882, -0.7882, -0.7961],\n",
      "          [-0.6863, -0.7098, -0.7255,  ..., -0.7882, -0.7804, -0.7961],\n",
      "          ...,\n",
      "          [-0.8275, -0.8353, -0.8431,  ...,  0.7725,  0.8588,  0.8824],\n",
      "          [-0.8275, -0.8275, -0.8275,  ...,  0.8431,  0.8745,  0.8745],\n",
      "          [-0.8196, -0.8118, -0.8196,  ...,  0.8353,  0.8510,  0.8667]],\n",
      "\n",
      "         [[-0.8196, -0.8353, -0.8353,  ..., -0.7961, -0.7882, -0.7961],\n",
      "          [-0.8196, -0.8353, -0.8353,  ..., -0.7961, -0.7961, -0.8039],\n",
      "          [-0.8196, -0.8353, -0.8353,  ..., -0.7961, -0.7882, -0.8039],\n",
      "          ...,\n",
      "          [-0.8667, -0.8745, -0.8824,  ...,  0.3961,  0.6392,  0.7020],\n",
      "          [-0.8667, -0.8667, -0.8667,  ...,  0.5451,  0.7098,  0.7020],\n",
      "          [-0.8588, -0.8510, -0.8588,  ...,  0.5843,  0.7255,  0.7020]],\n",
      "\n",
      "         [[-0.8824, -0.8902, -0.8745,  ..., -0.8275, -0.8196, -0.8275],\n",
      "          [-0.8824, -0.8902, -0.8745,  ..., -0.8275, -0.8275, -0.8353],\n",
      "          [-0.8824, -0.8902, -0.8745,  ..., -0.8275, -0.8196, -0.8353],\n",
      "          ...,\n",
      "          [-0.8980, -0.9059, -0.9137,  ...,  0.0980,  0.4667,  0.5529],\n",
      "          [-0.8980, -0.8980, -0.8980,  ...,  0.3098,  0.5765,  0.5608],\n",
      "          [-0.8902, -0.8824, -0.8902,  ...,  0.3961,  0.6235,  0.5686]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8118,  0.8275,  0.8196,  ...,  0.7882,  0.7961,  0.7961],\n",
      "          [ 0.8118,  0.8275,  0.8196,  ...,  0.8039,  0.7961,  0.7961],\n",
      "          [ 0.8118,  0.8275,  0.8275,  ...,  0.8039,  0.8039,  0.8039],\n",
      "          ...,\n",
      "          [ 0.5451,  0.5451,  0.5216,  ..., -0.7804, -0.7647, -0.7647],\n",
      "          [ 0.5059,  0.5294,  0.5451,  ..., -0.7725, -0.7725, -0.7569],\n",
      "          [ 0.4667,  0.4980,  0.5294,  ..., -0.7725, -0.7725, -0.7569]],\n",
      "\n",
      "         [[ 0.8196,  0.8353,  0.8275,  ...,  0.7882,  0.7961,  0.7961],\n",
      "          [ 0.8196,  0.8353,  0.8275,  ...,  0.8039,  0.7961,  0.7961],\n",
      "          [ 0.8196,  0.8353,  0.8353,  ...,  0.8039,  0.8039,  0.8039],\n",
      "          ...,\n",
      "          [ 0.5529,  0.5529,  0.5294,  ..., -0.8118, -0.7961, -0.7961],\n",
      "          [ 0.5137,  0.5373,  0.5529,  ..., -0.8039, -0.8039, -0.7882],\n",
      "          [ 0.4745,  0.5059,  0.5373,  ..., -0.8039, -0.8039, -0.7882]],\n",
      "\n",
      "         [[ 0.8510,  0.8667,  0.8588,  ...,  0.8039,  0.8118,  0.8118],\n",
      "          [ 0.8510,  0.8667,  0.8588,  ...,  0.8196,  0.8118,  0.8118],\n",
      "          [ 0.8510,  0.8667,  0.8667,  ...,  0.8196,  0.8196,  0.8196],\n",
      "          ...,\n",
      "          [ 0.5922,  0.5922,  0.5686,  ..., -0.8353, -0.8196, -0.8196],\n",
      "          [ 0.5529,  0.5765,  0.5922,  ..., -0.8275, -0.8275, -0.8118],\n",
      "          [ 0.5137,  0.5451,  0.5765,  ..., -0.8275, -0.8275, -0.8118]]]]) \n",
      "\n",
      "y_ref:\n",
      " tensor([0, 1])\n",
      "X.shape, Y.shape and Y:\n",
      "torch.Size([2, 3, 256, 256]) torch.Size([2]) tensor([0, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H.shape before: torch.Size([2, 512, 1, 1])\n",
      "H.shape after: torch.Size([2, 512])\n",
      "len(out) before: 2\n",
      "out.shape after: torch.Size([2, 2, 64])\n",
      "OUT: tensor([[[ 1.1713, -1.1371,  0.2181, -0.2989, -0.7462,  0.3311,  0.5409,\n",
      "           1.6859,  1.7946, -0.4707, -1.5976, -1.6116, -0.8940,  0.8856,\n",
      "           0.1836, -0.4243,  1.5599,  0.0772, -0.8860,  1.0079,  0.5985,\n",
      "          -1.1520,  0.9832, -1.3237,  0.4058,  0.1356,  1.1079, -0.8748,\n",
      "           1.6796, -0.5946, -0.6884,  0.5382, -1.3920, -0.8834,  1.6290,\n",
      "          -0.6876,  0.0090,  1.6941, -0.4298,  0.1530, -2.2129,  0.9818,\n",
      "          -1.2147, -1.1813, -0.5949, -0.4926, -0.9399, -0.3763,  0.4755,\n",
      "          -2.0352, -1.7954,  0.1015,  0.5432,  0.1582,  0.6301,  0.9467,\n",
      "          -1.4342, -1.3404,  1.9331, -1.5649,  0.1566,  1.0164, -1.9589,\n",
      "          -0.4186],\n",
      "         [-0.3219, -1.4319, -0.3994,  1.4013, -0.0781,  0.4606,  0.9882,\n",
      "           1.1066, -1.8467,  0.1585,  1.7096, -1.6057,  0.8242,  0.2532,\n",
      "           0.6031,  0.3341, -0.7456,  0.7144,  0.7835,  2.4832, -0.4540,\n",
      "           0.4331, -0.7016,  0.9983,  0.3759,  0.7094, -1.9019, -0.2641,\n",
      "          -0.6796, -0.9898,  0.5418,  0.0674, -0.7560,  0.6959, -0.9773,\n",
      "           0.6438, -0.1610, -0.8088,  0.0536,  0.3052,  0.2063,  0.0106,\n",
      "           0.2880,  0.9206,  0.5301, -0.9837,  0.1734, -1.1604,  0.1792,\n",
      "          -0.7033, -1.4580, -1.1315, -0.8609,  1.1123,  0.2560, -0.4325,\n",
      "          -1.5310,  1.6257, -0.2232,  0.3325,  2.1275, -0.0079, -1.5997,\n",
      "           1.2711]],\n",
      "\n",
      "        [[ 0.4501, -0.2607, -0.0352,  0.6296,  1.2117,  0.2001,  1.1039,\n",
      "           2.5885,  0.4479,  0.1713, -1.7132, -0.1509, -0.5539,  0.4723,\n",
      "           0.2415, -0.8158,  1.7236, -0.4681, -0.8444,  1.3343,  1.7385,\n",
      "          -1.6360, -0.3496, -0.9915, -0.4344,  0.4507, -0.3910, -1.2205,\n",
      "           1.5018, -0.0328, -0.8304,  0.4027, -1.6473, -1.3541,  1.9987,\n",
      "           1.4659,  0.8065,  1.0961, -0.3525,  0.2491, -0.4688,  2.2685,\n",
      "          -1.3619, -0.2650, -1.9781, -0.0433,  1.4020,  0.5366,  0.4304,\n",
      "          -1.9408, -1.5493, -1.5015,  0.6872,  0.7698,  0.5283,  2.6445,\n",
      "          -0.5877, -0.6533,  1.8039,  0.2819,  1.3877,  0.2406, -1.6063,\n",
      "          -2.4003],\n",
      "         [-0.8216, -1.0778, -0.4992, -0.0137, -0.3354, -0.5576,  0.0508,\n",
      "           2.6689, -2.7473,  0.6649,  2.1998, -0.3055,  0.5111,  1.1715,\n",
      "          -0.5310,  1.5740, -0.3429,  1.6152,  0.4943,  1.8748, -1.0641,\n",
      "           0.2774, -0.6686,  0.3015, -0.0922, -0.0091, -3.4861, -1.9983,\n",
      "          -0.8082, -2.5637,  0.9561, -1.0554, -0.6361,  0.1015, -0.8741,\n",
      "          -0.4494,  0.9654, -1.4886, -1.5606,  0.3962, -1.0300, -1.8460,\n",
      "           0.7820,  0.2963,  2.0057, -0.1408, -0.9108, -0.2224, -0.2283,\n",
      "          -2.3702, -3.0597, -1.7717, -3.0052,  1.4072,  1.4856, -0.3239,\n",
      "          -2.0644,  2.2874,  0.4251,  1.2344,  2.6074, -0.7849, -2.7916,\n",
      "           2.4380]]])\n",
      "IDX: tensor([0, 1])\n",
      "Working on my_experiment/results/video_ref.mp4...\n",
      "X.shape, Y.shape and Y:\n",
      "torch.Size([2, 3, 256, 256]) torch.Size([2]) tensor([1, 2])\n",
      "H.shape before: torch.Size([2, 512, 1, 1])\n",
      "H.shape after: torch.Size([2, 512])\n",
      "len(out) before: 2\n",
      "out.shape after: torch.Size([2, 2, 64])\n",
      "OUT: tensor([[[ 1.1713, -1.1371,  0.2181, -0.2989, -0.7462,  0.3311,  0.5409,\n",
      "           1.6859,  1.7946, -0.4707, -1.5976, -1.6116, -0.8940,  0.8856,\n",
      "           0.1836, -0.4243,  1.5599,  0.0772, -0.8860,  1.0079,  0.5985,\n",
      "          -1.1520,  0.9832, -1.3237,  0.4058,  0.1356,  1.1079, -0.8748,\n",
      "           1.6796, -0.5946, -0.6884,  0.5382, -1.3920, -0.8834,  1.6290,\n",
      "          -0.6876,  0.0090,  1.6941, -0.4298,  0.1530, -2.2129,  0.9818,\n",
      "          -1.2147, -1.1813, -0.5949, -0.4926, -0.9399, -0.3763,  0.4755,\n",
      "          -2.0352, -1.7954,  0.1015,  0.5432,  0.1582,  0.6301,  0.9467,\n",
      "          -1.4342, -1.3404,  1.9331, -1.5649,  0.1566,  1.0164, -1.9589,\n",
      "          -0.4186],\n",
      "         [-0.3219, -1.4319, -0.3994,  1.4013, -0.0781,  0.4606,  0.9882,\n",
      "           1.1066, -1.8467,  0.1585,  1.7096, -1.6057,  0.8242,  0.2532,\n",
      "           0.6031,  0.3341, -0.7456,  0.7144,  0.7835,  2.4832, -0.4540,\n",
      "           0.4331, -0.7016,  0.9983,  0.3759,  0.7094, -1.9019, -0.2641,\n",
      "          -0.6796, -0.9898,  0.5418,  0.0674, -0.7560,  0.6959, -0.9773,\n",
      "           0.6438, -0.1610, -0.8088,  0.0536,  0.3052,  0.2063,  0.0106,\n",
      "           0.2880,  0.9206,  0.5301, -0.9837,  0.1734, -1.1604,  0.1792,\n",
      "          -0.7033, -1.4580, -1.1315, -0.8609,  1.1123,  0.2560, -0.4325,\n",
      "          -1.5310,  1.6257, -0.2232,  0.3325,  2.1275, -0.0079, -1.5997,\n",
      "           1.2711]],\n",
      "\n",
      "        [[ 0.4501, -0.2607, -0.0352,  0.6296,  1.2117,  0.2001,  1.1039,\n",
      "           2.5885,  0.4479,  0.1713, -1.7132, -0.1509, -0.5539,  0.4723,\n",
      "           0.2415, -0.8158,  1.7236, -0.4681, -0.8444,  1.3343,  1.7385,\n",
      "          -1.6360, -0.3496, -0.9915, -0.4344,  0.4507, -0.3910, -1.2205,\n",
      "           1.5018, -0.0328, -0.8304,  0.4027, -1.6473, -1.3541,  1.9987,\n",
      "           1.4659,  0.8065,  1.0961, -0.3525,  0.2491, -0.4688,  2.2685,\n",
      "          -1.3619, -0.2650, -1.9781, -0.0433,  1.4020,  0.5366,  0.4304,\n",
      "          -1.9408, -1.5493, -1.5015,  0.6872,  0.7698,  0.5283,  2.6445,\n",
      "          -0.5877, -0.6533,  1.8039,  0.2819,  1.3877,  0.2406, -1.6063,\n",
      "          -2.4003],\n",
      "         [-0.8216, -1.0778, -0.4992, -0.0137, -0.3354, -0.5576,  0.0508,\n",
      "           2.6689, -2.7473,  0.6649,  2.1998, -0.3055,  0.5111,  1.1715,\n",
      "          -0.5310,  1.5740, -0.3429,  1.6152,  0.4943,  1.8748, -1.0641,\n",
      "           0.2774, -0.6686,  0.3015, -0.0922, -0.0091, -3.4861, -1.9983,\n",
      "          -0.8082, -2.5637,  0.9561, -1.0554, -0.6361,  0.1015, -0.8741,\n",
      "          -0.4494,  0.9654, -1.4886, -1.5606,  0.3962, -1.0300, -1.8460,\n",
      "           0.7820,  0.2963,  2.0057, -0.1408, -0.9108, -0.2224, -0.2283,\n",
      "          -2.3702, -3.0597, -1.7717, -3.0052,  1.4072,  1.4856, -0.3239,\n",
      "          -2.0644,  2.2874,  0.4251,  1.2344,  2.6074, -0.7849, -2.7916,\n",
      "           2.4380]]])\n",
      "IDX: tensor([0, 1])\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 182, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 73, in main\n",
      "    solver.sample(loaders)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/solver.py\", line 190, in sample\n",
      "    utils.video_ref(nets_ema, args, src.x, ref.x, ref.y, fname)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/utils.py\", line 209, in video_ref\n",
      "    s_ref = nets.style_encoder(x_ref, y_ref)\n",
      "  File \"/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/media/hdd3/oguz/stargan-v2/core/model.py\", line 260, in forward\n",
      "    s = out[idx, y]  # (batch, style_dim)\n",
      "IndexError: index 2 is out of bounds for dimension 1 with size 2\n"
     ]
    }
   ],
   "source": [
    "!python main.py --mode sample --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
    "                --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
    "                --result_dir my_experiment/results \\\n",
    "                --src_dir my_experiment/src \\\n",
    "                --ref_dir my_experiment/ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With avg faces aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='my_experiment/ref', result_dir='my_experiment/results', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='my_experiment/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from expr/checkpoints/celeba_hq/100000_nets_ema.ckpt...\n",
      "InputFetcher._fetch_inputs method called..\n",
      "self.LOADER: <torch.utils.data.dataloader.DataLoader object at 0x7f2e68123fd0>\n",
      "InputFetcher._fetch_inputs method called..\n",
      "self.LOADER: <torch.utils.data.dataloader.DataLoader object at 0x7f2e680c4198>\n",
      "Working on my_experiment/results/reference_avg_aligned_at_src.jpg...\n",
      "REF_y: tensor([1, 2], device='cuda:0') ----> tensor([0, 1], device='cuda:0')\n",
      "NCHW: 4 3 256 256\n",
      "/home/hamdi_ug/anaconda3/envs/strgn/lib/python3.6/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "len(MASKS): 2 MASKS[0].SHAPE torch.Size([4, 1, 256, 256])\n",
      "\n",
      "X_REF.SHAPE: torch.Size([2, 3, 256, 256]) Y_REF.SHAPE: torch.Size([2])\n",
      "X.shape, Y.shape and Y:\n",
      "torch.Size([2, 3, 256, 256]) torch.Size([2]) tensor([0, 1], device='cuda:0')\n",
      "H.shape before: torch.Size([2, 512, 1, 1])\n",
      "H.shape after: torch.Size([2, 512])\n",
      "len(out) before: 2\n",
      "out.shape after: torch.Size([2, 2, 64])\n",
      "OUT: tensor([[[ 1.1713, -1.1371,  0.2181, -0.2989, -0.7462,  0.3311,  0.5409,\n",
      "           1.6859,  1.7946, -0.4707, -1.5976, -1.6116, -0.8940,  0.8856,\n",
      "           0.1836, -0.4243,  1.5599,  0.0772, -0.8860,  1.0079,  0.5985,\n",
      "          -1.1520,  0.9832, -1.3237,  0.4058,  0.1356,  1.1079, -0.8748,\n",
      "           1.6796, -0.5946, -0.6884,  0.5382, -1.3920, -0.8834,  1.6290,\n",
      "          -0.6876,  0.0090,  1.6941, -0.4298,  0.1530, -2.2129,  0.9818,\n",
      "          -1.2147, -1.1813, -0.5949, -0.4926, -0.9399, -0.3763,  0.4755,\n",
      "          -2.0352, -1.7954,  0.1015,  0.5432,  0.1582,  0.6301,  0.9467,\n",
      "          -1.4342, -1.3404,  1.9331, -1.5649,  0.1566,  1.0164, -1.9589,\n",
      "          -0.4186],\n",
      "         [-0.3219, -1.4319, -0.3994,  1.4013, -0.0781,  0.4606,  0.9882,\n",
      "           1.1066, -1.8467,  0.1585,  1.7096, -1.6057,  0.8242,  0.2532,\n",
      "           0.6031,  0.3341, -0.7456,  0.7144,  0.7835,  2.4832, -0.4540,\n",
      "           0.4331, -0.7016,  0.9983,  0.3759,  0.7094, -1.9019, -0.2641,\n",
      "          -0.6796, -0.9898,  0.5418,  0.0674, -0.7560,  0.6959, -0.9773,\n",
      "           0.6438, -0.1610, -0.8088,  0.0536,  0.3052,  0.2063,  0.0106,\n",
      "           0.2880,  0.9206,  0.5301, -0.9837,  0.1734, -1.1604,  0.1792,\n",
      "          -0.7033, -1.4580, -1.1315, -0.8609,  1.1123,  0.2560, -0.4325,\n",
      "          -1.5310,  1.6257, -0.2232,  0.3325,  2.1275, -0.0079, -1.5997,\n",
      "           1.2711]],\n",
      "\n",
      "        [[ 0.9720, -1.1535,  1.4238, -0.8048,  0.6904,  0.2686,  0.8107,\n",
      "           2.7219,  1.8601, -0.1293, -0.4463, -0.5425, -0.3317,  0.1070,\n",
      "           0.0539, -0.8237,  1.4947, -0.2818, -1.2205,  0.5682,  1.2194,\n",
      "          -0.6325,  0.1871, -0.9434,  0.0213,  0.6913,  0.0730, -1.2544,\n",
      "           1.7644,  0.4236, -0.2921,  0.8333, -2.5376, -2.4676,  1.5539,\n",
      "           0.9751,  0.3687,  1.5679,  0.0484,  0.1946, -1.6904,  0.8383,\n",
      "          -1.2427, -0.7383, -2.1356, -0.2745,  1.1918,  0.5939, -0.1022,\n",
      "          -2.1235, -0.7148, -1.9290, -0.1570,  0.6251,  0.8141,  2.4029,\n",
      "          -0.5638, -1.5020,  2.2096, -0.1035,  1.4177,  0.3899, -1.4984,\n",
      "          -2.5245],\n",
      "         [-1.5859, -0.8443,  0.0596, -0.2741, -0.9314,  0.7997,  0.9188,\n",
      "           2.2584, -2.5288,  0.2803,  2.2092, -0.7454,  1.1605,  0.6373,\n",
      "           0.5833,  1.1958, -0.3551,  1.5484,  0.4268,  2.9004, -1.1209,\n",
      "          -0.5285, -1.7533,  0.3542,  0.4167,  0.9998, -3.4420, -0.3611,\n",
      "          -1.1645, -2.0651,  1.1998, -0.0554, -0.7389,  0.2662, -0.6094,\n",
      "           0.2746,  0.2858, -0.9194, -1.2720,  0.3066, -0.2065, -0.7954,\n",
      "           0.9751,  1.2617, -0.1461, -0.6361, -0.6287, -0.7954, -0.4421,\n",
      "          -2.1276, -3.2984, -1.7640, -2.0282,  1.2132,  1.4546, -0.4907,\n",
      "          -1.2654,  2.4529, -0.3942,  0.7888,  2.9713, -0.0334, -2.6268,\n",
      "           2.2695]]], device='cuda:0')\n",
      "IDX: tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "!python main.py --mode sample --num_domains 2 --resume_iter 100000 --w_hpf 1 \\\n",
    "                --checkpoint_dir expr/checkpoints/celeba_hq \\\n",
    "                --result_dir my_experiment/results \\\n",
    "                --src_dir my_experiment/src \\\n",
    "                --ref_dir my_experiment/ref"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrand = torch.rand(2,2,64)\n",
    "myrand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7793, 0.3772, 0.4308, 0.3869, 0.5443, 0.4000, 0.4574, 0.5934,\n",
       "          0.1729, 0.0755, 0.4928, 0.6684, 0.7016, 0.1845, 0.3060, 0.9569,\n",
       "          0.2110, 0.7333, 0.3520, 0.3173, 0.3193, 0.1222, 0.7255, 0.3517,\n",
       "          0.6050, 0.2843, 0.1982, 0.4004, 0.1843, 0.6621, 0.8105, 0.6392,\n",
       "          0.9831, 0.3116, 0.5312, 0.2806, 0.3168, 0.9464, 0.5875, 0.8133,\n",
       "          0.1055, 0.3122, 0.4302, 0.9097, 0.9343, 0.9893, 0.9850, 0.3345,\n",
       "          0.4819, 0.2236, 0.0819, 0.0367, 0.0435, 0.5614, 0.2986, 0.0892,\n",
       "          0.8893, 0.3656, 0.8465, 0.8617, 0.3651, 0.5198, 0.5578, 0.0386],\n",
       "         [0.9484, 0.7974, 0.9653, 0.3330, 0.9607, 0.3231, 0.7316, 0.2038,\n",
       "          0.2111, 0.0964, 0.5475, 0.1617, 0.8815, 0.7566, 0.4892, 0.5627,\n",
       "          0.4429, 0.1831, 0.5331, 0.8958, 0.3032, 0.2912, 0.8584, 0.3405,\n",
       "          0.1537, 0.1266, 0.8241, 0.1835, 0.9775, 0.4292, 0.4751, 0.7782,\n",
       "          0.7757, 0.7318, 0.7579, 0.9410, 0.1495, 0.2643, 0.8352, 0.4293,\n",
       "          0.5662, 0.0732, 0.1222, 0.6085, 0.0907, 0.0756, 0.5655, 0.2913,\n",
       "          0.2926, 0.4304, 0.4298, 0.2176, 0.3385, 0.9999, 0.3080, 0.5624,\n",
       "          0.6247, 0.3392, 0.4510, 0.9101, 0.3946, 0.9683, 0.8032, 0.3442]],\n",
       "\n",
       "        [[0.4472, 0.0845, 0.5080, 0.1746, 0.8909, 0.7239, 0.0047, 0.7002,\n",
       "          0.6727, 0.4566, 0.8801, 0.7556, 0.0012, 0.4300, 0.9798, 0.7387,\n",
       "          0.0707, 0.6169, 0.7004, 0.2815, 0.6626, 0.3866, 0.1183, 0.5838,\n",
       "          0.5258, 0.4482, 0.3396, 0.9189, 0.2965, 0.0232, 0.7120, 0.5786,\n",
       "          0.0975, 0.9814, 0.8792, 0.7643, 0.2140, 0.1486, 0.0359, 0.1041,\n",
       "          0.8626, 0.8863, 0.5333, 0.6024, 0.7751, 0.8306, 0.9925, 0.6231,\n",
       "          0.1975, 0.6323, 0.9510, 0.8421, 0.4906, 0.4069, 0.8316, 0.8235,\n",
       "          0.2043, 0.0697, 0.6296, 0.3588, 0.1573, 0.1278, 0.7449, 0.3416],\n",
       "         [0.5238, 0.6846, 0.0329, 0.4335, 0.0569, 0.4047, 0.4386, 0.8216,\n",
       "          0.3981, 0.6476, 0.1804, 0.6916, 0.1046, 0.0135, 0.5037, 0.5543,\n",
       "          0.8378, 0.8621, 0.8899, 0.7728, 0.4248, 0.0203, 0.8497, 0.4720,\n",
       "          0.7846, 0.6528, 0.3748, 0.1865, 0.1892, 0.0495, 0.4485, 0.3090,\n",
       "          0.8198, 0.7973, 0.1694, 0.9552, 0.0800, 0.4037, 0.7752, 0.4408,\n",
       "          0.6833, 0.7786, 0.5245, 0.1071, 0.5514, 0.6300, 0.1685, 0.2631,\n",
       "          0.0161, 0.7861, 0.2506, 0.6059, 0.7662, 0.9370, 0.4974, 0.4744,\n",
       "          0.6724, 0.8184, 0.4574, 0.4213, 0.3761, 0.6332, 0.2756, 0.4110]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7793, 0.3772, 0.4308, 0.3869, 0.5443, 0.4000, 0.4574, 0.5934,\n",
       "          0.1729, 0.0755, 0.4928, 0.6684, 0.7016, 0.1845, 0.3060, 0.9569,\n",
       "          0.2110, 0.7333, 0.3520, 0.3173, 0.3193, 0.1222, 0.7255, 0.3517,\n",
       "          0.6050, 0.2843, 0.1982, 0.4004, 0.1843, 0.6621, 0.8105, 0.6392,\n",
       "          0.9831, 0.3116, 0.5312, 0.2806, 0.3168, 0.9464, 0.5875, 0.8133,\n",
       "          0.1055, 0.3122, 0.4302, 0.9097, 0.9343, 0.9893, 0.9850, 0.3345,\n",
       "          0.4819, 0.2236, 0.0819, 0.0367, 0.0435, 0.5614, 0.2986, 0.0892,\n",
       "          0.8893, 0.3656, 0.8465, 0.8617, 0.3651, 0.5198, 0.5578, 0.0386],\n",
       "         [0.9484, 0.7974, 0.9653, 0.3330, 0.9607, 0.3231, 0.7316, 0.2038,\n",
       "          0.2111, 0.0964, 0.5475, 0.1617, 0.8815, 0.7566, 0.4892, 0.5627,\n",
       "          0.4429, 0.1831, 0.5331, 0.8958, 0.3032, 0.2912, 0.8584, 0.3405,\n",
       "          0.1537, 0.1266, 0.8241, 0.1835, 0.9775, 0.4292, 0.4751, 0.7782,\n",
       "          0.7757, 0.7318, 0.7579, 0.9410, 0.1495, 0.2643, 0.8352, 0.4293,\n",
       "          0.5662, 0.0732, 0.1222, 0.6085, 0.0907, 0.0756, 0.5655, 0.2913,\n",
       "          0.2926, 0.4304, 0.4298, 0.2176, 0.3385, 0.9999, 0.3080, 0.5624,\n",
       "          0.6247, 0.3392, 0.4510, 0.9101, 0.3946, 0.9683, 0.8032, 0.3442]],\n",
       "\n",
       "        [[0.4472, 0.0845, 0.5080, 0.1746, 0.8909, 0.7239, 0.0047, 0.7002,\n",
       "          0.6727, 0.4566, 0.8801, 0.7556, 0.0012, 0.4300, 0.9798, 0.7387,\n",
       "          0.0707, 0.6169, 0.7004, 0.2815, 0.6626, 0.3866, 0.1183, 0.5838,\n",
       "          0.5258, 0.4482, 0.3396, 0.9189, 0.2965, 0.0232, 0.7120, 0.5786,\n",
       "          0.0975, 0.9814, 0.8792, 0.7643, 0.2140, 0.1486, 0.0359, 0.1041,\n",
       "          0.8626, 0.8863, 0.5333, 0.6024, 0.7751, 0.8306, 0.9925, 0.6231,\n",
       "          0.1975, 0.6323, 0.9510, 0.8421, 0.4906, 0.4069, 0.8316, 0.8235,\n",
       "          0.2043, 0.0697, 0.6296, 0.3588, 0.1573, 0.1278, 0.7449, 0.3416],\n",
       "         [0.5238, 0.6846, 0.0329, 0.4335, 0.0569, 0.4047, 0.4386, 0.8216,\n",
       "          0.3981, 0.6476, 0.1804, 0.6916, 0.1046, 0.0135, 0.5037, 0.5543,\n",
       "          0.8378, 0.8621, 0.8899, 0.7728, 0.4248, 0.0203, 0.8497, 0.4720,\n",
       "          0.7846, 0.6528, 0.3748, 0.1865, 0.1892, 0.0495, 0.4485, 0.3090,\n",
       "          0.8198, 0.7973, 0.1694, 0.9552, 0.0800, 0.4037, 0.7752, 0.4408,\n",
       "          0.6833, 0.7786, 0.5245, 0.1071, 0.5514, 0.6300, 0.1685, 0.2631,\n",
       "          0.0161, 0.7861, 0.2506, 0.6059, 0.7662, 0.9370, 0.4974, 0.4744,\n",
       "          0.6724, 0.8184, 0.4574, 0.4213, 0.3761, 0.6332, 0.2756, 0.4110]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrand[torch.tensor([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7793, 0.3772, 0.4308, 0.3869, 0.5443, 0.4000, 0.4574, 0.5934, 0.1729,\n",
       "         0.0755, 0.4928, 0.6684, 0.7016, 0.1845, 0.3060, 0.9569, 0.2110, 0.7333,\n",
       "         0.3520, 0.3173, 0.3193, 0.1222, 0.7255, 0.3517, 0.6050, 0.2843, 0.1982,\n",
       "         0.4004, 0.1843, 0.6621, 0.8105, 0.6392, 0.9831, 0.3116, 0.5312, 0.2806,\n",
       "         0.3168, 0.9464, 0.5875, 0.8133, 0.1055, 0.3122, 0.4302, 0.9097, 0.9343,\n",
       "         0.9893, 0.9850, 0.3345, 0.4819, 0.2236, 0.0819, 0.0367, 0.0435, 0.5614,\n",
       "         0.2986, 0.0892, 0.8893, 0.3656, 0.8465, 0.8617, 0.3651, 0.5198, 0.5578,\n",
       "         0.0386],\n",
       "        [0.5238, 0.6846, 0.0329, 0.4335, 0.0569, 0.4047, 0.4386, 0.8216, 0.3981,\n",
       "         0.6476, 0.1804, 0.6916, 0.1046, 0.0135, 0.5037, 0.5543, 0.8378, 0.8621,\n",
       "         0.8899, 0.7728, 0.4248, 0.0203, 0.8497, 0.4720, 0.7846, 0.6528, 0.3748,\n",
       "         0.1865, 0.1892, 0.0495, 0.4485, 0.3090, 0.8198, 0.7973, 0.1694, 0.9552,\n",
       "         0.0800, 0.4037, 0.7752, 0.4408, 0.6833, 0.7786, 0.5245, 0.1071, 0.5514,\n",
       "         0.6300, 0.1685, 0.2631, 0.0161, 0.7861, 0.2506, 0.6059, 0.7662, 0.9370,\n",
       "         0.4974, 0.4744, 0.6724, 0.8184, 0.4574, 0.4213, 0.3761, 0.6332, 0.2756,\n",
       "         0.4110]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrand[torch.tensor([0,1]), [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = [1,2]\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_yy = np.asarray(yy) - 1\n",
    "new_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fd690e2e7182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyrand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 1 with size 2"
     ]
    }
   ],
   "source": [
    "myrand[torch.tensor([0,1]), yy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7793, 0.3772, 0.4308, 0.3869, 0.5443, 0.4000, 0.4574, 0.5934, 0.1729,\n",
       "         0.0755, 0.4928, 0.6684, 0.7016, 0.1845, 0.3060, 0.9569, 0.2110, 0.7333,\n",
       "         0.3520, 0.3173, 0.3193, 0.1222, 0.7255, 0.3517, 0.6050, 0.2843, 0.1982,\n",
       "         0.4004, 0.1843, 0.6621, 0.8105, 0.6392, 0.9831, 0.3116, 0.5312, 0.2806,\n",
       "         0.3168, 0.9464, 0.5875, 0.8133, 0.1055, 0.3122, 0.4302, 0.9097, 0.9343,\n",
       "         0.9893, 0.9850, 0.3345, 0.4819, 0.2236, 0.0819, 0.0367, 0.0435, 0.5614,\n",
       "         0.2986, 0.0892, 0.8893, 0.3656, 0.8465, 0.8617, 0.3651, 0.5198, 0.5578,\n",
       "         0.0386],\n",
       "        [0.5238, 0.6846, 0.0329, 0.4335, 0.0569, 0.4047, 0.4386, 0.8216, 0.3981,\n",
       "         0.6476, 0.1804, 0.6916, 0.1046, 0.0135, 0.5037, 0.5543, 0.8378, 0.8621,\n",
       "         0.8899, 0.7728, 0.4248, 0.0203, 0.8497, 0.4720, 0.7846, 0.6528, 0.3748,\n",
       "         0.1865, 0.1892, 0.0495, 0.4485, 0.3090, 0.8198, 0.7973, 0.1694, 0.9552,\n",
       "         0.0800, 0.4037, 0.7752, 0.4408, 0.6833, 0.7786, 0.5245, 0.1071, 0.5514,\n",
       "         0.6300, 0.1685, 0.2631, 0.0161, 0.7861, 0.2506, 0.6059, 0.7662, 0.9370,\n",
       "         0.4974, 0.4744, 0.6724, 0.8184, 0.4574, 0.4213, 0.3761, 0.6332, 0.2756,\n",
       "         0.4110]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrand[torch.tensor([0,1]), new_yy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
